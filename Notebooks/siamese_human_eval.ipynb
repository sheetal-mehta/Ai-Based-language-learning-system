{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import audio_dataset_from_directory\n",
        "import numpy as np\n",
        "import librosa"
      ],
      "metadata": {
        "id": "SwbqWZGPhfth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_audio_file(file_path):\n",
        "    # Load an audio file as a tensor, assume the file is a WAV file\n",
        "    audio_binary = tf.io.read_file(file_path)\n",
        "    audio, sample_rate = tf.audio.decode_wav(audio_binary)\n",
        "    # Only use the first channel if it's stereo\n",
        "    audio = audio[:, 0]\n",
        "    return audio, sample_rate\n",
        "\n",
        "\n",
        "def preprocess_audio_mfps(audio, sample_rate):\n",
        "    # Cast audio to float32 and normalize\n",
        "    audio = tf.cast(audio, tf.float32)\n",
        "    audio = audio / 32768.0  # Normalize audio\n",
        "\n",
        "    # Extract mel-frequency power spectra\n",
        "    def _extract_mel(audio):\n",
        "        # Compute mel-frequency power spectra\n",
        "        stfts = tf.signal.stft(audio, frame_length=1024, frame_step=512, fft_length=1024)\n",
        "        spectrograms = tf.abs(stfts)\n",
        "\n",
        "        num_spectrogram_bins = stfts.shape[-1]\n",
        "        lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 128\n",
        "        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "            num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hertz, upper_edge_hertz)\n",
        "\n",
        "        mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n",
        "        mel_spectrograms = tf.reshape(mel_spectrograms, [1, -1, 128])  # Reshape for batch dimension if needed\n",
        "        return mel_spectrograms\n",
        "\n",
        "    # Use tf.py_function to allow for eager execution of the extraction\n",
        "    mel_spectra = tf.py_function(_extract_mel, [audio], tf.float32)\n",
        "    return mel_spectra\n",
        "\n",
        "def pad_sequence(seq):\n",
        "    # Pad the sequence to the maximum length found in the training data\n",
        "    padded_seq = tf.pad(seq, paddings=[[0, 0], [0, max_length - tf.shape(seq)[1]], [0, 0]], constant_values=0)\n",
        "    return padded_seq\n"
      ],
      "metadata": {
        "id": "LYRh7dJCGJML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def contrastive_loss(y_true, y_pred, margin=1):\n",
        "    # Calculate the Euclidean distance between the two outputs\n",
        "    square_pred = tf.square(y_pred)\n",
        "    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
        "    return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
        "\n",
        "# Define cosine_similarity function as it's used in your Lambda layer\n",
        "def cosine_similarity(vectors):\n",
        "    x, y = vectors\n",
        "    x = K.l2_normalize(x, axis=-1)\n",
        "    y = K.l2_normalize(y, axis=-1)\n",
        "    return K.sum(x * y, axis=-1, keepdims=True)\n"
      ],
      "metadata": {
        "id": "6bA0FLsqGJkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name_m4a = \"/content/Achtee-irfan.m4a\"\n",
        "file_name_wav = \"/content/Achtee-irfan.wav\"\n",
        "base_file = \"/content/Q1201502.wav\""
      ],
      "metadata": {
        "id": "Xxb3NKKrJ_Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIadmUiBCY8H"
      },
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "import audioread\n",
        "import numpy as np\n",
        "\n",
        "# Function to load M4A file\n",
        "def load_m4a(filename):\n",
        "    with audioread.audio_open(filename) as f:\n",
        "        data = np.hstack([np.frombuffer(chunk, dtype='int16') for chunk in f])\n",
        "        return data, f.samplerate\n",
        "\n",
        "# Load your M4A file\n",
        "data, samplerate = load_m4a(file_name_m4a)\n",
        "\n",
        "# Convert it to WAV using soundfile\n",
        "sf.write(file_name_wav, data, samplerate, format='WAV', subtype='PCM_16')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of how to use these functions\n",
        "\n",
        "max_length = 402\n",
        "file_path = file_name_wav\n",
        "audio, sample_rate = load_audio_file(file_path)\n",
        "processed_audio = preprocess_audio_mfps(audio, sample_rate)\n",
        "processed_padded = pad_sequence(processed_audio)\n",
        "\n",
        "file_path_base = base_file\n",
        "audio_base, sample_rate_base = load_audio_file(file_path_base)\n",
        "processed_audio_base = preprocess_audio_mfps(audio_base, sample_rate_base)\n",
        "processed_padded_base = pad_sequence(processed_audio_base)\n",
        "\n",
        "\n",
        "# # Load the saved Siamese model\n",
        "# model_path = 'best_model.h5'\n",
        "# siamese_model = tf.keras.models.load_model(model_path)\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import backend as K  # Ensure backend is imported\n",
        "\n",
        "\n",
        "# When loading the model, you now also need to register the cosine_similarity function\n",
        "siamese_model = load_model('best_model_5-9.h5', custom_objects={'contrastive_loss': contrastive_loss, 'cosine_similarity': cosine_similarity})\n",
        "\n",
        "# Register the custom loss function and load the model\n",
        "#siamese_model = load_model('best_model_5-9.h5', custom_objects={'contrastive_loss': contrastive_loss})\n",
        "\n",
        "# Suppose you have another processed audio tensor, reference_audio, to compare against\n",
        "# Here you should provide your model with both samples as a pair\n",
        "output = siamese_model([processed_padded, processed_padded_base])  # Assuming your model takes a list of two inputs\n",
        "\n",
        "# The output typically could be a similarity score or a classification result\n",
        "print(\"Model output:\", output.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isR8wIc9GPgN",
        "outputId": "4fecae33-99d0-4dce-dd35-d319d384043e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output: [[0.76158553]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# color coding which letter or sound pronouncing wrong."
      ],
      "metadata": {
        "id": "pSbY7CN1hXZQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}